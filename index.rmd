---
#title: "README"
#author: "Marco Rozgic"
#date: "3/21/2020"
output: html_document
pagetitle: "COVID-19 outbreak analysis in Germany with R"

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pathData = "/Users/marcorozgic/Documents/FunRStuff/CovidAnalysis"
library(tidyverse)
#md_document
# package to handle date data types, which are allways hell
library(lubridate)

# this package has some nice themes for graphics which I find appealing
library(see)

# allows for great annotaions using our data making the code transferable
library(glue)

# nice package to arrange multiple plots
library(patchwork)

# helps us to make interactive plots
library(plotly)

# make even nicer plots
library(ggforce)

# a package containing an ODE solver for the SIR equation
library(deSolve)

# epidemiology package
library(EpiEstim)

#######
source(paste0(pathData,"/humanNumbers.R"))
#######
```

# COVID-19 outbreak analysis in Germany with R

<https://github.com/rozgicm/CovidAnalysis>


The conducted analysis follows the posts by Tim Churches, starting with his post in February 2020:
<https://timchurches.github.io/blog/posts/2020-02-18-analysing-covid-19-2019-ncov-outbreak-data-with-r-part-1/#estimating-changes-in-the-effective-reproduction-number>

The code is slightly changed, some graphs are tweaked. All in all this is supposed to help scientists as well as non-scientists to gain insights and conduct their own analysis of the situation. The main code is found in **covidAnalysis.R**. I will try to show some results here on the main page. Please, feel free to contribute.


## Disclaimer
I am **not** a medical doctor, I am only a data-dude who wants to help citizen data scientist to stay informed and check the numbers we are confronted with every day. 
If you,  on the other hand, are someone who understands more about epidemiology, feel  free to use all you find here. Remember, most of it is presented in a much better way by Tim Churches. If you feel interested in doing some data analysis yourself and want to add, please feel free, that's what GitHub is for.


## Data Acquisition
Data are pulled from JHU GitHub archive <https://github.com/CSSEGISandData/COVID-19>. R allows for a fairly easy way to get the data from the GitHub archive. The JHU data are nicely formatted and thus suitable for a quick analysis.

```{r readDataFromJHU, echo=TRUE, message=FALSE, warning=FALSE}
jhuUrl = paste("https://raw.githubusercontent.com/CSSEGISandData/",
                 "COVID-19/master/csse_covid_19_data/", "csse_covid_19_time_series/",
                 "time_series_covid19_confirmed_global.csv", sep = "")

dat =  read_csv(jhuUrl) %>% rename(province = "Province/State",
                                    country = "Country/Region")

head(dat)
```

As can be seen, the data is in 'wide' format. I will be using the **tidyverse** package a lot, I mean a lot (!!), thus I will reshape the data into 'long' format:

```{r datLOng, echo=TRUE, message=FALSE, warning=FALSE}
datLong = dat %>%
  filter(country == "Germany") %>%  
  pivot_longer(-c(province,country, Lat, Long),
               names_to = "Date",
               values_to = "cumulative_cases")
head(datLong)
```

To get a feeling how the number of infected people is evolving we can visualize the number of cumulative cases quickly. Since exponential growth is expected it makes sense to visualize the log-transformed number of cases.

```{r GermanyFigs, echo=TRUE, message=FALSE, warning=FALSE}
datLong = datLong %>%
  select(-c(province, Lat, Long)) %>%
  mutate(Date = mdy(Date)) %>% 
  filter(cumulative_cases != 0) %>%
  mutate(incident_cases = c(0, diff(cumulative_cases)),
         myDay = 1:nrow(.),
         myWeek = week(Date)-3 )

p1 = datLong %>% ggplot(aes(x=Date, y = cumulative_cases)) +
  geom_line() +
  geom_point(shape = "x") +
  labs(title = glue("Number of COVID-19 infections in {datLong$country[1]}"),
       subtitle = glue("data ranging from {min(datLong$Date)} to {max(datLong$Date)}")
       ) +
  theme_lucid()

p2 = datLong %>% ggplot(aes(x=Date, y = log(cumulative_cases))) +
  geom_line() +
  geom_point(shape = "x") +
  labs(title = glue("Number of COVID-19 infections in {datLong$country[1]}"),
       subtitle = glue("data ranging from {min(datLong$Date)} to {max(datLong$Date)}"),
       caption = "log scale plot"
       ) +
  theme_lucid()

p1 %>% ggplotly(., dynamicTicks = TRUE)

p2 %>% ggplotly(., dynamicTicks = TRUE)
```


Some people are interested in the growth of cases after for example the 100th case. In most cases I see those figures with absolute numbers. I think this is kind of misleading. Using the the **wppExplorer** package I was able to obtain the total number of people in each European country.


```{r plotEurope, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
datWorld =  dat %>% pivot_longer(-c(province,country, Lat, Long),
                          names_to = "Date", 
                          values_to = "cumulative_cases")
europe = read_csv2(file =paste0(pathData, "/countriesOfEurope.csv"))

# consider "Mainland" only for the time beeing
datEurope = filter(datWorld, country %in% europe$Countries)

datEurope = datEurope %>% 
  mutate(Date = mdy(Date)) %>% 
  group_by(country, Date) %>% 
    summarise(sumCumCases = sum(cumulative_cases)) %>% 
  ungroup() 


tPop = readRDS(file = paste0(pathData, "/tPop.RDS"))
cCodes = readRDS(file = paste0(pathData, "/countryCodes.RDS"))

datEurope = datEurope %>% 
  left_join(., cCodes %>%  select(name, charcode), 
            by = c("country"="name")) %>% 
  left_join(., tPop %>% 
              filter(Year =="2020") %>%
              select(-Year),
            by ="charcode") %>% 
  mutate(value = value * 1000)


datEurope = datEurope %>% filter(sumCumCases > 100) %>% 
  group_by(country) %>%
  group_modify(~{
    .x$daySince100 = 1:nrow(.x)
    return(.x)
  })%>% ungroup()


(datEurope %>% 
  ggplot(aes(x= daySince100, y = (sumCumCases/value)*100, colour = country, group = country) )+
           geom_line() +
           labs(x = "Number of days after reaching 100 cases",
                y =  "Percentage of population per country",
                title = "Development of cases in european countries after reaching 100 infections") +
           theme_lucid() +
  scale_colour_flat_d() )%>% ggplotly()
```



## Implemented Features
As to this day `r lubridate::today()` only simple models are considered. That means, that no modelling of measures that are undertaken in included. So called 'physical distancing' is not included in any model, yet. I hope I will get to it, or maybe someone can include it ;-).


### Linear modelling
When assuming exponential growth, it is a good idea to fit a linear model to the log transformed data. Above figure suggests that it is sensible to start modelling somewhere in the middle/end of February.

```{r linModel, echo=TRUE, message=FALSE, warning=FALSE}
myLinearModel = lm(log(cumulative_cases) ~ myDay,
                   datLong %>%
                   filter(Date >= as.Date("2020-03-20"))
                   )
summary(myLinearModel)
linModelDf = broom::tidy(myLinearModel)
datLong %>% filter(Date >= as.Date("2020-03-20") ) %>%
  ggplot(aes(x=myDay, y= log(cumulative_cases))) +
  geom_smooth(method = lm) +
  geom_point() +
  labs(title = glue("fitted linear model with intercept {round(linModelDf$estimate[1],2)} and slope {round(linModelDf$estimate[2],2)}"))+
  theme_lucid()
```

The computed slope can be used to compute growth rates (as far as I understood this is called $R_{0}$ in epidemiology). From the above linear model follows 

$R^{\text{linear}}_0=$ `r round(exp(linModelDf$estimate[2]),2)`

Further we can compute things like doubling times, by doing something like $$t_{\text{double}} = \frac{\operatorname{log}\left ( 2 \right ) }{\operatorname{log} \left ( R^{\text{linear}}_0 \right) }$$.

```{r doubleTimes, echo=TRUE, message=FALSE, warning=FALSE}
log(2)/linModelDf$estimate[2]
```

And of course we can also make predictions. Please be careful, these are only predictions from a linear model!

```{r predictions, echo=TRUE, message=FALSE, warning=FALSE}
startDay =  datLong %>%
  filter(Date >= as.Date("2020-03-20")) %>% pull(myDay) %>% min()
endDay = datLong %>%
  filter(Date >= as.Date("2020-03-20")) %>% pull(myDay) %>% max()

startDate = datLong %>%
  filter(Date >= as.Date("2020-03-20")) %>% pull(Date) %>% min()

endDate = datLong %>%
  filter(Date >= as.Date("2020-03-20")) %>% pull(Date) %>% max()

predDF = broom::tidy(predict(myLinearModel,
                             newdata = data.frame(myDay = startDay:(endDay+7)),
                             interval = "prediction"))

predDF$Date = seq(startDate,
                  max(datLong$Date)+days(7),
                  by = "day")


p4 = p1 + geom_ribbon(data = predDF,
                 inherit.aes = FALSE,
                 aes(ymin=exp(lwr), ymax = exp(upr), x = Date),
                 fill = "grey2", alpha =0.25) +
  geom_line(data = predDF,  inherit.aes = FALSE,
            aes(x= Date, y= exp(fit), colour = "fit")) +
  annotate("text",
           y = c(max(exp(predDF$fit)), max(exp(predDF$lwr)),max(exp(predDF$upr))),
           x = max(predDF$Date)+days(2),
           label = c(glue({round(max(exp(predDF$fit)))}),
                     glue({round(max(exp(predDF$lwr)))}),
                     glue({round(max(exp(predDF$upr)))})
                     )
           )+
  labs(title = glue("Number of COVID-19 infections in {datLong$country[1]} with a 7 day fit") )+
  theme(legend.title = element_blank())

p4 + facet_zoom(xlim= c(endDate, max(predDF$Date)))
```



### SIR modelling
A more sophisticated way to model the outbreak can be performed by applying the SIR-Model
(**S**usceptible **I**nfectious **R**ecovered). The model is based on an ODE system. See the code and Tim Churches' posts for more details. However, the following can be obtained:
```{r include=FALSE, paged.print=TRUE}
datLong = datLong %>% filter(Date >=  as.Date("2020-03-20"))

numPeople = 1000*83149.3
sirStartDate = min(datLong$Date)

#datLong = datLong %>% filter(Date < as.Date("2020-03-26"))

init = c(S= numPeople - datLong$cumulative_cases[1],
         I = datLong$cumulative_cases[1],
         R = 0)

# first we need a function which translates the ODE's stated in the SIR model

SIR = function(time, state, parameters) {
  par = as.list(c(state, parameters))
  with(par, {
    dS = -beta * I * S/numPeople
    dI = beta * I * S/numPeople - gamma * I
    dR = gamma * I
    return(list(c(dS, dI, dR)))
  })
}

RSS = function(parameters) {
  names(parameters) = c("beta", "gamma")
  out = ode(y = init, times = datLong$myDay, func = SIR, parms = parameters)
  fit = out[, 3]
  return(sum((datLong$cumulative_cases - fit)^2))
}


Opt = optim(c(0.5, 0.5),
             RSS,
             method = "L-BFGS-B",
             lower = c(0,0),
             upper = c(1, 1)
             )
t = 1:100

optParams = set_names(Opt$par, "beta", "gamma")

fittedCumulativeIncidenceDf = data.frame(ode(y = init,
                                             times = t,
                                              func = SIR,
                                             parms = optParams)) %>%
  mutate(Date = min(datLong$Date) + days(time-1))


dat = left_join(fittedCumulativeIncidenceDf, datLong ,by=c("Date"))


```
```{r SIRPic, echo=FALSE, warning=FALSE}

dat %>% select(Date, cumulative_cases, I) %>%
  rename(cCases =cumulative_cases, fittedCCases = I) %>%
  pivot_longer(-Date) %>%
  ggplot(aes(x=Date, y=value, colour = name)) +
  geom_line() +
  geom_point(shape = "x") +
  labs(title = glue("SIR-Model based projection of COVID-19 infections in {datLong$country[1]}"),
       subtitle = glue("data ranging from {min(dat$Date)} to {max(dat$Date)}"),
       caption = glue("fitted data from SIR model,\n
                      computed R0 ={round(optParams[1]/optParams[2],2)},\n
                      fitted point of reduce: At {dat$Date[which(dat$I==max(dat$I))]} with {humanNumbers(round(dat$I[which(dat$I==max(dat$I))]))} infections"),
       y = "Cumulative Cases") +

  scale_y_continuous(labels = humanNumbers)+
  theme_lucid()+
  scale_color_material_d() +
  facet_zoom( y = name =="cCases",
              xlim = c(min(datLong$Date), max(datLong$Date)),
              horizontal = FALSE)
```


### 






<!-- ### Estimating Changing Reproduction Numbers -->
<!-- With  the EpiEstim package changing reproduction rates can be computed. So far only constant changerates have been considered. -->


